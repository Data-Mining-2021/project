{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_tfidf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lW699bvOYy"
      },
      "source": [
        "Clone the project repo containing the Twitter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgmfzzhCmeq9",
        "outputId": "6331709a-554d-4a3f-e95d-e3871edd1733"
      },
      "source": [
        "!git clone https://github.com/Data-Mining-2021/project.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LiufTkbwGUb"
      },
      "source": [
        "Get all imports at once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlDL7_2Kv3KF",
        "outputId": "0f5723a2-9beb-4f53-a1f1-d9bc4676b437"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from joblib import dump, load\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JUqQC4KPhTH"
      },
      "source": [
        "Filter Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r76nBwW5PaOf"
      },
      "source": [
        "# https://stackoverflow.com/a/49146722/330558\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "# filter out non-english tweets - also checks for NaN and tweets only containing emojis\n",
        "def filter_tweets(tweets_df):\n",
        "    for index in tweets_df.index:\n",
        "        currText = tweets_df.loc[index, 'Text']\n",
        "        if currText != currText or not remove_emoji(currText).strip() or detect(currText) != 'en':\n",
        "            tweets_df = tweets_df.drop([index])\n",
        "    return tweets_df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYOhLOPyruxG"
      },
      "source": [
        "Load in the data and then filter the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0yPfViErs3C"
      },
      "source": [
        "nontrump_df = pd.read_csv('/content/project/Results/all_tweets_notrump_blanksremoved.csv')\n",
        "alltweets_df = pd.read_csv('/content/project/Results/all_tweets.csv')\n",
        "trump_df = pd.read_csv('/content/project/Results/trump_tweets.csv')\n",
        "#nontrump_df = pd.read_csv('/content/project/all_tweets_notrump_blanksremoved.csv') #use later when clone isn't being a bitch\n",
        "\n",
        "#filter the dataframe for each data set\n",
        "nontrump_filtered_df = filter_tweets(nontrump_df)\n",
        "nontrump_text = nontrump_filtered_df['Text']\n",
        "\n",
        "alltweets_filtered_df = filter_tweets(alltweets_df)\n",
        "alltweets_text = alltweets_filtered_df['Text']\n",
        "\n",
        "trump_filtered_df = filter_tweets(trump_df)\n",
        "trump_text = trump_filtered_df['Text']\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdQwLhvPw7yt"
      },
      "source": [
        "Generate kmeans cluster file from TFIDF vectorization of tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqYGXjL7Pb_"
      },
      "source": [
        "def tokenize_tweet(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token) and len(token) > 3:\n",
        "            filtered_tokens.append(token)\n",
        "    return filtered_tokens\n",
        "\n",
        "# vectorize into tfidf format (1-grams and 2-grams)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=200000, max_df=0.8, tokenizer=tokenize_tweet, use_idf=True, stop_words='english')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Uc-TWxbmvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a0f385-4a0c-4a25-fcba-cb5c23bb0519"
      },
      "source": [
        "#perform Kmeans for the non-trump tweets\n",
        "tfidf_matrix_nontrump = vectorizer.fit_transform(nontrump_text)\n",
        "\n",
        "# cluster using k-means++\n",
        "num_clusters_nontrump = 7\n",
        "km = KMeans(n_clusters=num_clusters_nontrump)\n",
        "km.fit(tfidf_matrix_nontrump)\n",
        "clusters_nontrump = km.labels_.tolist()\n",
        "\n",
        "# export cluster data\n",
        "dump(km, 'nontrump_clusters_7.pkl')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nontrump_clusters_7.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNiEL9BlbnX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06fe750-9265-4ae0-c568-003d3f17e574"
      },
      "source": [
        "#perform Kmeans for the trump tweets with 7 and 10 clusters\n",
        "tfidf_matrix_trump = vectorizer.fit_transform(trump_text)\n",
        "\n",
        "# cluster using k-means++ with 7 clusters\n",
        "num_clusters_trump1 = 7\n",
        "km = KMeans(n_clusters=num_clusters_trump1)\n",
        "km.fit(tfidf_matrix_trump)\n",
        "clusters_trump1 = km.labels_.tolist()\n",
        "# export cluster data\n",
        "dump(km, 'trump_clusters_7.pkl')\n",
        "\n",
        "\n",
        "# cluster using k-means++ with 10 clusters\n",
        "num_clusters_trump2 = 10\n",
        "km = KMeans(n_clusters=num_clusters_trump2)\n",
        "km.fit(tfidf_matrix_trump)\n",
        "clusters_trump2 = km.labels_.tolist()\n",
        "# export cluster data\n",
        "dump(km, 'trump_clusters_10.pkl')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trump_clusters_10.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kr4Z_uHboli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7637837e-2a88-400a-fab8-c2079798faef"
      },
      "source": [
        "#perform Kmeans for the all tweets\n",
        "tfidf_matrix_all = vectorizer.fit_transform(alltweets_text)\n",
        "dump(tfidf_matrix_all, 'all_tweets_vectorized.pkl')\n",
        "\n",
        "# cluster using k-means++\n",
        "num_clusters_all = 7\n",
        "km = KMeans(n_clusters=num_clusters_all)\n",
        "km.fit(tfidf_matrix_all)\n",
        "clusters_all = km.labels_.tolist()\n",
        "\n",
        "# export cluster data\n",
        "dump(km, 'alltweets_clusters_7.pkl')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alltweets_clusters_7.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmqBb6_-t91x"
      },
      "source": [
        "Organize TFIDF clusters into a dataframe w/ corresponding tweet data (username, country)\n",
        "\n",
        "Also print the results for each data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXqgAIsWddmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1431c0b0-d585-4d9f-ea87-b3d6ca0c627e"
      },
      "source": [
        "#show cluster occurrence by country for non trump tweets\n",
        "# reload the cluster data\n",
        "km_nontrump = load('nontrump_clusters_7.pkl')\n",
        "clusters_nontrump = km_nontrump.labels_.tolist()\n",
        "\n",
        "#define the vocabulary\n",
        "nontrump_vocab = vectorizer.vocabulary_\n",
        "\n",
        "# enter tfidf cluster data and corresponding twitter users into dataframe\n",
        "tweets_nontrump = { 'cluster': clusters_nontrump, 'username': nontrump_filtered_df['Username'].tolist(), 'country': nontrump_filtered_df['Country'].tolist() }\n",
        "cluster_nontrump_df = pd.DataFrame(tweets_nontrump, index = [clusters_nontrump], columns = ['cluster', 'username', 'country'])\n",
        "\n",
        "print('Cluster occurrence based on country:')\n",
        "grouped_nontrump = cluster_nontrump_df['cluster']\n",
        "grouped_nontrump = cluster_nontrump_df['cluster'].groupby(cluster_nontrump_df['country'])\n",
        "grouped_nontrump.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster occurrence based on country:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country       cluster\n",
              "Australia     5          1223\n",
              "              3             1\n",
              "              4             1\n",
              "Canada        5          5061\n",
              "              4           987\n",
              "              3            71\n",
              "              2             2\n",
              "Chile         5           350\n",
              "India         5           543\n",
              "Israel        5          3285\n",
              "              4            56\n",
              "              2            37\n",
              "              3             1\n",
              "Liberia       5            30\n",
              "New Zealand   5           322\n",
              "Nigeria       5          1036\n",
              "              2             1\n",
              "South Africa  5          6260\n",
              "              6           357\n",
              "              0           209\n",
              "              3             4\n",
              "              2             1\n",
              "South Korea   5           199\n",
              "UN            5          2711\n",
              "              2             1\n",
              "USA           5          7774\n",
              "              2           918\n",
              "              3           440\n",
              "              1           285\n",
              "Name: cluster, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4cmVmBss0VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35a8919-4792-4acc-8f1c-12953556b956"
      },
      "source": [
        "#display the cluster data for nontrump tweets\n",
        "num_words = 10\n",
        "print(f'Top {num_words} terms per cluster:\\n')\n",
        "\n",
        "# sort cluster centers by proximity to centroid\n",
        "order_centroids = km_nontrump.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i in range(num_clusters_nontrump):\n",
        "  print(f'Cluster {i} words:', end='')\n",
        "  for index in order_centroids[i, :num_words]:\n",
        "    print(f' {terms[index]},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} usernames:', end='')\n",
        "  for u in cluster_nontrump_df.loc[i]['username'].unique():\n",
        "    print(f' {u},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} countries:', end='')\n",
        "  for c in cluster_nontrump_df.loc[i]['country'].unique():\n",
        "    print(f' {c},', end='')\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 terms per cluster:\n",
            "\n",
            "Cluster 0 words: fully power, ahmed saif, fully lived, aime hadrien, place china, country teams, success assured., reined away, veterans hispanic, reach learn,\n",
            "Cluster 0 usernames: DrZweliMkhize,\n",
            "Cluster 0 countries: South Africa,\n",
            "\n",
            "Cluster 1 words: truly equal, yesterday meeting, time years, value women, quality time, treatment help, moment holiday, necessary says, services widening, performed immigrant,\n",
            "Cluster 1 usernames: NYGovCuomo,\n",
            "Cluster 1 countries: USA,\n",
            "\n",
            "Cluster 2 words: underway currently, know thinking, know taking, reached critical, real worldenvironmentalhealthday, pandemic adopted, amazing news, wish grant, need advice, wish ignore,\n",
            "Cluster 2 usernames: JoeBiden, SpeakerPelosi, LeaderMcConnell, NYGovCuomo, GovRonDeSantis, JustinTrudeau, fordnation, CyrilRamaphosa, MBuhari, PresidentRuvi, IsraeliPM, antonioguterres,\n",
            "Cluster 2 countries: USA, Canada, South Africa, Nigeria, Israel, UN,\n",
            "\n",
            "Cluster 3 words: week explosion, bipartisan natlgovsassoc, week international, number votes, navy involved, heard head, values unite, navy leadership, reality addressing, numbers eastern,\n",
            "Cluster 3 usernames: JoeBiden, SpeakerPelosi, NYGovCuomo, GovRonDeSantis, JustinTrudeau, fordnation, DrZweliMkhize, IsraeliPM, GregHuntMP,\n",
            "Cluster 3 countries: USA, Canada, South Africa, Israel, Australia,\n",
            "\n",
            "Cluster 4 words: ones september11, nigeria stands, nigeria specifically, understand claiming, receive coronavirus, receive channel, ones family, week explosion, travelers covid19, numbers economy,\n",
            "Cluster 4 usernames: CanadianPM, IsraeliPM, ScottMorrisonMP,\n",
            "Cluster 4 countries: Canada, Israel, Australia,\n",
            "\n",
            "Cluster 5 words: global movement, prison based, nation economic, trainees, partisan abuse, work public, g7parliament meeting, ones family, fighting lgbtq, times rise,\n",
            "Cluster 5 usernames: JoeBiden, SpeakerPelosi, LeaderMcConnell, NYGovCuomo, GovRonDeSantis, Canada, JustinTrudeau, CanadianPM, fordnation, CyrilRamaphosa, DrZweliMkhize, GeorgeWeahOff, MBuhari, femigbaja, PresidentRuvi, IsraeliPM, nsitharaman, TheBlueHouseENG, ScottMorrisonMP, GregHuntMP, jacindaardern, AndrewLittleMP, mbachelet, antonioguterres, AminaJMohammed, volkan_bozkir,\n",
            "Cluster 5 countries: USA, Canada, South Africa, Liberia, Nigeria, Israel, India, South Korea, Australia, New Zealand, Chile, UN,\n",
            "\n",
            "Cluster 6 words: truly pro-people, percent boko, truly equal, percentage recipients, perduesenate senate, declined, decriminalisation, help seniors, reviewed county, campaign thank,\n",
            "Cluster 6 usernames: DrZweliMkhize,\n",
            "Cluster 6 countries: South Africa,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-6JuhmdeJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcbee66-4a9b-4f5c-94c6-e1785991f12b"
      },
      "source": [
        "#show cluster occurrence by country for trump tweets\n",
        "# reload the cluster data\n",
        "km_trump = load('trump_clusters_7.pkl')\n",
        "clusters_trump = km_trump.labels_.tolist()\n",
        "\n",
        "#define the vocabulary\n",
        "trump_vocab = vectorizer.vocabulary_\n",
        "\n",
        "# enter tfidf cluster data and corresponding twitter users into dataframe\n",
        "tweets_trump = { 'cluster': clusters_trump, 'username': trump_filtered_df['Username'].tolist(), 'country': trump_filtered_df['Country'].tolist() }\n",
        "cluster_trump_df = pd.DataFrame(tweets_trump, index = [clusters_trump], columns = ['cluster', 'username', 'country'])\n",
        "\n",
        "print('Cluster occurrence based on country:')\n",
        "grouped_trump = cluster_trump_df['cluster']\n",
        "grouped_trump = cluster_trump_df['cluster'].groupby(cluster_trump_df['country'])\n",
        "grouped_trump.value_counts()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster occurrence based on country:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country  cluster\n",
              "Trump    0          3850\n",
              "         3           305\n",
              "         5           257\n",
              "         1           237\n",
              "         2           200\n",
              "         6            76\n",
              "         4            31\n",
              "Name: cluster, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2kAKClNtCY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e88961c-f7cf-4bbf-8776-98945cf1aa4f"
      },
      "source": [
        "#display the cluster data for trump tweets\n",
        "num_words = 10\n",
        "print(f'Top {num_words} terms per cluster:\\n')\n",
        "\n",
        "# sort cluster centers by proximity to centroid\n",
        "order_centroids = km_trump.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i in range(num_clusters_trump1):\n",
        "  print(f'Cluster {i} words:', end='')\n",
        "  for index in order_centroids[i, :num_words]:\n",
        "    print(f' {terms[index]},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} usernames:', end='')\n",
        "  for u in cluster_trump_df.loc[i]['username'].unique():\n",
        "    print(f' {u},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} countries:', end='')\n",
        "  for c in cluster_trump_df.loc[i]['country'].unique():\n",
        "    print(f' {c},', end='')\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 terms per cluster:\n",
            "\n",
            "Cluster 0 words: days suggestion, argentine president, history police, epidemic, mubarak president, ceremonies, including health, moon manifest, mn08, critical,\n",
            "Cluster 0 usernames: theRealDonaldTrump,\n",
            "Cluster 0 countries: Trump,\n",
            "\n",
            "Cluster 1 words: campaign destroy, cooperating creates, campaign maximum, monitor symptoms, monitor manage, administered date, lincoln alexander, lincoln, moving devastating, message leaders,\n",
            "Cluster 1 usernames: theRealDonaldTrump,\n",
            "Cluster 1 countries: Trump,\n",
            "\n",
            "Cluster 2 words: mn08, following states, mobilized politics, ahead sunday, israeli citizens, ahead meeting, israeli people, kelli, helping families, help thousands,\n",
            "Cluster 2 usernames: theRealDonaldTrump,\n",
            "Cluster 2 countries: Trump,\n",
            "\n",
            "Cluster 3 words: correct listen, great yesterday, corps fellows, functions, green transportation, experts legal, epidemic, experts safe, borders work, days suggestion,\n",
            "Cluster 3 usernames: theRealDonaldTrump,\n",
            "Cluster 3 countries: Trump,\n",
            "\n",
            "Cluster 4 words: days suggestion, death great, distribution retail, dcexaminer, australia share, dear friend, covid19 details, covid19 demands, covid19 deepened, covid19 decisions,\n",
            "Cluster 4 usernames: theRealDonaldTrump,\n",
            "Cluster 4 countries: Trump,\n",
            "\n",
            "Cluster 5 words: convenes roundtable, lahore, laid vision, multiple circumstances, android, covid update, imfnews kgeorgieva, municipal rules, foodstuffs, discuss recent,\n",
            "Cluster 5 usernames: theRealDonaldTrump,\n",
            "Cluster 5 countries: Trump,\n",
            "\n",
            "Cluster 6 words: held consultations, canada remains, greater toll, narendramodi talks, narendramodi strong, held economic, contracted coronavirus, doing wear, great yesterday, coordinating,\n",
            "Cluster 6 usernames: theRealDonaldTrump,\n",
            "Cluster 6 countries: Trump,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBzex5TZe8Zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b23479e-b9e1-40c6-f3bb-19eb14c4034a"
      },
      "source": [
        "#show cluster occurrence by country for all tweets\n",
        "# reload the cluster data\n",
        "km_alltweets = load('alltweets_clusters_7.pkl')\n",
        "clusters_alltweets = km_alltweets.labels_.tolist()\n",
        "\n",
        "#define the vocabulary\n",
        "alltweets_vocab = vectorizer.vocabulary_\n",
        "\n",
        "# enter tfidf cluster data and corresponding twitter users into dataframe\n",
        "tweets_alltweets = { 'cluster': clusters_alltweets, 'username': alltweets_filtered_df['Username'].tolist(), 'country': alltweets_filtered_df['Country'].tolist() }\n",
        "cluster_alltweets_df = pd.DataFrame(tweets_alltweets, index = [clusters_alltweets], columns = ['cluster', 'username', 'country'])\n",
        "\n",
        "print('Cluster occurrence based on country:')\n",
        "grouped_alltweets = cluster_alltweets_df['cluster']\n",
        "grouped_alltweets = cluster_alltweets_df['cluster'].groupby(cluster_alltweets_df['country'])\n",
        "grouped_alltweets.value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster occurrence based on country:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country       cluster\n",
              "Australia     4          1003\n",
              "              1           221\n",
              "              0             1\n",
              "              6             1\n",
              "Canada        4          4411\n",
              "              0           990\n",
              "              1           475\n",
              "              3           174\n",
              "              6            71\n",
              "Chile         4           308\n",
              "              1            42\n",
              "India         4           530\n",
              "              1             6\n",
              "Israel        4          2986\n",
              "              1           239\n",
              "              0           150\n",
              "Liberia       4            29\n",
              "              1             1\n",
              "New Zealand   4           308\n",
              "              1            14\n",
              "Nigeria       4           982\n",
              "              1            55\n",
              "South Africa  4          5549\n",
              "              1           710\n",
              "              5           367\n",
              "              2           209\n",
              "              6             4\n",
              "South Korea   4           197\n",
              "              1             2\n",
              "Trump         4          4944\n",
              "              1            17\n",
              "              6             3\n",
              "UN            4          2568\n",
              "              1           142\n",
              "USA           4          8026\n",
              "              1           644\n",
              "              6           450\n",
              "              5           285\n",
              "Name: cluster, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShQydqJatT4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddd4bbd-bad8-42cf-8afa-02457f17a613"
      },
      "source": [
        "#display the cluster data for all tweets\n",
        "num_words = 10\n",
        "print(f'Top {num_words} terms per cluster:\\n')\n",
        "\n",
        "# sort cluster centers by proximity to centroid\n",
        "order_centroids = km_alltweets.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i in range(num_clusters_all):\n",
        "  print(f'Cluster {i} words:', end='')\n",
        "  for index in order_centroids[i, :num_words]:\n",
        "    print(f' {terms[index]},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} usernames:', end='')\n",
        "  for u in cluster_alltweets_df.loc[i]['username'].unique():\n",
        "    print(f' {u},', end='')\n",
        "\n",
        "  print(f'\\nCluster {i} countries:', end='')\n",
        "  for c in cluster_alltweets_df.loc[i]['country'].unique():\n",
        "    print(f' {c},', end='')\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 terms per cluster:\n",
            "\n",
            "Cluster 0 words: prime minister, prime, minister, minister justin, justin trudeau, trudeau, justin, watch, today prime, live prime,\n",
            "Cluster 0 usernames: JustinTrudeau, CanadianPM, fordnation, IsraeliPM, ScottMorrisonMP,\n",
            "Cluster 0 countries: Canada, Israel, Australia,\n",
            "\n",
            "Cluster 1 words: health, care, health care, public, public health, workers, mental, mental health, minister, covid19,\n",
            "Cluster 1 usernames: JoeBiden, SpeakerPelosi, LeaderMcConnell, NYGovCuomo, GovRonDeSantis, Canada, JustinTrudeau, CanadianPM, fordnation, CyrilRamaphosa, DrZweliMkhize, GeorgeWeahOff, MBuhari, femigbaja, PresidentRuvi, IsraeliPM, nsitharaman, TheBlueHouseENG, ScottMorrisonMP, GregHuntMP, AndrewLittleMP, mbachelet, antonioguterres, AminaJMohammed, volkan_bozkir, theRealDonaldTrump,\n",
            "Cluster 1 countries: USA, Canada, South Africa, Liberia, Nigeria, Israel, India, South Korea, Australia, New Zealand, Chile, UN, Trump,\n",
            "\n",
            "Cluster 2 words: covid alert, alert, covid, alert protect, ones community, start using, community start, protect loved, preserving today, phone fight,\n",
            "Cluster 2 usernames: DrZweliMkhize,\n",
            "Cluster 2 countries: South Africa,\n",
            "\n",
            "Cluster 3 words: premier ford, ford, premier, provides covid-19, ford provides, make announcement, ford minister, provides, covid-19 update, announcement,\n",
            "Cluster 3 usernames: fordnation,\n",
            "Cluster 3 countries: Canada,\n",
            "\n",
            "Cluster 4 words: people, thank, today, covid19, great, president, need, country, work, time,\n",
            "Cluster 4 usernames: JoeBiden, SpeakerPelosi, LeaderMcConnell, NYGovCuomo, GovRonDeSantis, Canada, JustinTrudeau, CanadianPM, fordnation, CyrilRamaphosa, DrZweliMkhize, GeorgeWeahOff, MBuhari, femigbaja, PresidentRuvi, IsraeliPM, nsitharaman, TheBlueHouseENG, ScottMorrisonMP, GregHuntMP, jacindaardern, AndrewLittleMP, mbachelet, antonioguterres, AminaJMohammed, volkan_bozkir, theRealDonaldTrump,\n",
            "Cluster 4 countries: USA, Canada, South Africa, Liberia, Nigeria, Israel, India, South Korea, Australia, New Zealand, Chile, UN, Trump,\n",
            "\n",
            "Cluster 5 words: total, total number, number, yesterday, today, number confirmed, number deaths, confirmed, confirmed covid19, deaths,\n",
            "Cluster 5 usernames: NYGovCuomo, DrZweliMkhize,\n",
            "Cluster 5 countries: USA, South Africa,\n",
            "\n",
            "Cluster 6 words: watch, briefing, watch live, live, holding, daily, updates, holding briefing, press, live press,\n",
            "Cluster 6 usernames: JoeBiden, SpeakerPelosi, NYGovCuomo, GovRonDeSantis, JustinTrudeau, fordnation, DrZweliMkhize, GregHuntMP, theRealDonaldTrump,\n",
            "Cluster 6 countries: USA, Canada, South Africa, Australia, Trump,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpIogNk5pyFW"
      },
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# #Make Trump 1 clusters to measure similarity between trump and other clusters\n",
        "# #vectorizer_trump = TfidfVectorizer(ngram_range=(1, 2), max_features=200000, max_df=0.8, tokenizer=tokenize_tweet, use_idf=True, stop_words='english')\n",
        "# tfidf_matrix_trump = vectorizer.fit_transform(trump_text)\n",
        "# svd = TruncatedSVD(100)\n",
        "# normalizer = Normalizer(copy=False)\n",
        "# lsa = make_pipeline(svd, normalizer)\n",
        "# tfidf_matrix_trump = lsa.fit_transform(tfidf_matrix_trump)\n",
        "# # export cluster data\n",
        "# dump(tfidf_matrix_trump, 'trump_tweets_vectorized_with_dimension_reduction.pkl')\n",
        "\n",
        "# num_clusters_trump1 = 1\n",
        "# km_trump = KMeans(n_clusters=num_clusters_trump1).fit(tfidf_matrix_trump)\n",
        "# dump(km_trump, 'trump_cluster_1.pkl')\n",
        "# trump_centroid = km_trump.cluster_centers_\n",
        "\n",
        "# num_clusters_nontrump = 7\n",
        "# #when run for the first time, uncomment the below line\n",
        "# # tfidf_matrix_nontrump = lsa.fit_transform(tfidf_matrix_nontrump)\n",
        "# dump(tfidf_matrix_nontrump, 'non_trump_tweets_vectorized_with_dimension_reduction.pkl')\n",
        "# km_nontrump = KMeans(n_clusters=num_clusters_nontrump)\n",
        "# km_nontrump.fit(tfidf_matrix_nontrump)\n",
        "# dump(km_nontrump, 'non_trump_cluster_dim_reduction_7.pkl')\n",
        "# non_trump_centroids = km_nontrump.cluster_centers_\n",
        "\n",
        "# for i in range(num_clusters_nontrump):\n",
        "#   non_trump_centroid = non_trump_centroids[i].reshape(1,-1)\n",
        "#   print(f'Cluster {i} similarity with trump tweets: ', end='')\n",
        "#   print(cosine_similarity(trump_centroid, non_trump_centroid)[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb0Le8XkH3-x",
        "outputId": "8048c7b7-782b-4f69-8e78-6dcfce377bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "km_trump = load('trump_cluster_1.pkl')\n",
        "trump_centroid = km_trump.cluster_centers_\n",
        "\n",
        "km_nontrump = load('non_trump_cluster_dim_reduction_7.pkl')\n",
        "non_trump_centroids = km_nontrump.cluster_centers_\n",
        "\n",
        "for i in range(num_clusters_nontrump):\n",
        "  non_trump_centroid = non_trump_centroids[i].reshape(1,-1)\n",
        "  print(f'Cluster {i} similarity with trump tweets: ', end='')\n",
        "  print(cosine_similarity(trump_centroid, non_trump_centroid)[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster 0 similarity with trump tweets: [0.45748614]\n",
            "Cluster 1 similarity with trump tweets: [0.34126566]\n",
            "Cluster 2 similarity with trump tweets: [0.23121215]\n",
            "Cluster 3 similarity with trump tweets: [0.2667449]\n",
            "Cluster 4 similarity with trump tweets: [0.26625446]\n",
            "Cluster 5 similarity with trump tweets: [0.29974988]\n",
            "Cluster 6 similarity with trump tweets: [0.0676599]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}